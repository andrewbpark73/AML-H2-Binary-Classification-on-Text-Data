{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s0DBGcZfs0FJ"
      },
      "outputs": [],
      "source": [
        "# e.g. if using google colab import drive, uncomment lines below\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LX0ia6JVtFjr"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression as sk_OLS\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD0dQabauB7z"
      },
      "source": [
        "# Part (a): Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uRBDrBxYtBbk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training data points: 7613\n",
            "Number of test data points: 3263\n",
            "Percentage of tweets about real disasters: 42.97%\n",
            "Percentage of tweets not about real disasters: 57.03%\n"
          ]
        }
      ],
      "source": [
        "#====================================================#\n",
        "# YOUR CODE HERE:\n",
        "#   Import train and test csv files.\n",
        "#   You should use the pd.read_csv function.\n",
        "#   You should set the index_col parameter to equal 'id'.\n",
        "#====================================================#\n",
        "\n",
        "train_data = pd.read_csv('train.csv', index_col='id')\n",
        "test_data  = pd.read_csv('test.csv', index_col='id')\n",
        "\n",
        "# Count the number of data points\n",
        "num_train_data_points = len(train_data)\n",
        "num_test_data_points = len(test_data)\n",
        "\n",
        "print(f\"Number of training data points: {num_train_data_points}\")\n",
        "print(f\"Number of test data points: {num_test_data_points}\")\n",
        "\n",
        "# Calculate the percentage of tweets that are about real disasters\n",
        "percentage_real_disasters = (train_data['target'].sum() / num_train_data_points) * 100\n",
        "percentage_not_real_disasters = 100 - percentage_real_disasters\n",
        "\n",
        "print(f\"Percentage of tweets about real disasters: {percentage_real_disasters:.2f}%\")\n",
        "print(f\"Percentage of tweets not about real disasters: {percentage_not_real_disasters:.2f}%\")\n",
        "\n",
        "#====================================================#\n",
        "# END YOUR CODE\n",
        "#====================================================#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dG7kzzuDvlBr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Shape: (7613, 3)\n",
            "Test Data Shape: (3263, 3)\n",
            "Number of labels = 1 in train dataset as percentage: 42.97%\n",
            "Number of labels = 0 in train dataset as percentage: 57.03%\n"
          ]
        }
      ],
      "source": [
        "#====================================================#\n",
        "# YOUR CODE HERE:\n",
        "#   Get the index values for X_train and y_train.\n",
        "#   Get the data values for X_train and y_train.\n",
        "#   Get the index values for X_test.\n",
        "#   Get the index values for y_test.\n",
        "#====================================================#\n",
        "\n",
        "# get train indices\n",
        "X_train_id = train_data.index\n",
        "y_train_id = train_data['target']\n",
        "# get train data\n",
        "X_train    = train_data.drop(columns=['target'])  # Remove the 'target' column\n",
        "y_train    = train_data['target']\n",
        "\n",
        "# get test indices\n",
        "X_test_id  = test_data.index\n",
        "# get test data\n",
        "X_test     = test_data\n",
        "\n",
        "#====================================================#\n",
        "# END YOUR CODE\n",
        "#====================================================#\n",
        "\n",
        "print(f\"Train Data Shape: {X_train.shape}\")\n",
        "print(f\"Test Data Shape: {X_test.shape}\")\n",
        "\n",
        "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_16NkNGt3Kx"
      },
      "source": [
        "### Part (a), Question 1: How many training and test data points are there?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uqBPKEYt7W5"
      },
      "source": [
        "### Answer: There are 7613 data points for training and 3263 data points for test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEVclzmqt9TF"
      },
      "source": [
        "### Part (a), Question 2: what percentage of the training tweets are of real disasters, and what percentage is not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J7911HiucTb"
      },
      "source": [
        "### Answer: The percentage for real disasters is 42.97%, and the percentage for not-real disasters is 57.03%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrzjUIXfuHEt"
      },
      "source": [
        "# Part (b): Split the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iy51Q0txuJpC"
      },
      "outputs": [],
      "source": [
        "#====================================================#\n",
        "# YOUR CODE HERE:\n",
        "#  You should use the sklearn.model_selection.train_test_split\n",
        "#     parameter to perform the train/development split\n",
        "#   Set the test_size to 0.30.\n",
        "#   Set the random_stat parameter to 42.\n",
        "#====================================================#\n",
        "\n",
        "X_train_orig   = train_test_split(\n",
        "    X_train, y_train, test_size=0.30, random_state=42)[0]\n",
        "X_develop_orig = train_test_split(\n",
        "    X_train, y_train, test_size=0.30, random_state=42)[1]\n",
        "y_train_orig   = train_test_split(\n",
        "    X_train, y_train, test_size=0.30, random_state=42)[2]\n",
        "y_develop_orig = train_test_split(\n",
        "    X_train, y_train, test_size=0.30, random_state=42)[3]\n",
        "\n",
        "#====================================================#\n",
        "# END YOUR CODE\n",
        "#====================================================#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSQOZqupuKGO"
      },
      "source": [
        "# Part (c): Preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wWpMOdJ2uipq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/andrewpark/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  You should complete the following function to obtain the pre-processed\n",
        "#  X_train and X_develop\n",
        "#  Note that we suggest you to do every sub-question in a dedicated Python\n",
        "#  function to make the code more structured and less error-prone.\n",
        "#  With a function, you can clearly test each part when you encounter an error.\n",
        "#  You can also create your own simple input data (e.g. just one sample) to\n",
        "#  test the correctness of a function.\n",
        "#========================================================================#\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "def pre_process(text):\n",
        "    # Convert text to lowercase\n",
        "    pre_processed = text.lower()\n",
        "    \n",
        "    # Lemmatize words\n",
        "    lemmatize = WordNetLemmatizer()\n",
        "    pre_processed = \" \".join([lemmatize.lemmatize(token) for token in pre_processed.split(\" \")])\n",
        "    \n",
        "    # Remove punctuation and @\n",
        "    pre_processed = \" \".join([word for word in pre_processed.split() if word.isalpha()])\n",
        "    \n",
        "    # Remove URLs\n",
        "    pre_processed = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', pre_processed, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    pre_processed = \" \".join([word for word in pre_processed.split() if not word in stop_words])\n",
        "    \n",
        "    #========================================================================#\n",
        "    #  This function should return the pre-processed data\n",
        "    #========================================================================#\n",
        "    return pre_processed # Feel free to change the variable name\n",
        "\n",
        "# Apply the pre_process_text function to the text columns of DataFrames\n",
        "X_train_preproc = X_train_orig.copy()\n",
        "X_train_preproc['text'] = X_train_orig['text'].apply(pre_process)\n",
        "\n",
        "X_develop_preproc = X_develop_orig.copy()\n",
        "X_develop_preproc['text'] = X_develop_orig['text'].apply(pre_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. I first converted the texts into lower case. This can make the data treatment simple afterwards.\n",
        "\n",
        "2. Then I lemmatized all the lowercase words.\n",
        "\n",
        "3. Removing punctuation and other symbols (e.g. @) by using '.isalpha()' method.\n",
        "\n",
        "4. Lastly, I removed URLs and stopwords to simplify the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GhiuEjdumEO"
      },
      "source": [
        "# Part (d): Bag of words model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fD4ZzrPQuo7B"
      },
      "outputs": [],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  You should complete the following function to obtain X_train and X_develop,\n",
        "#  whose \"text\" feature only contains 1 and 0 to indicate whether a word is in\n",
        "#  the tweet. At this point, you should only be constructing feature vectors\n",
        "#  for each data point using the text in the “text” column.\n",
        "#  You should ignore the “keyword” and “location” columns for now.\n",
        "#========================================================================#\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = None\n",
        "\n",
        "def bag_of_word(data, min_df=1):\n",
        "    global vectorizer\n",
        "    # Initialize the CountVectorizer with binary=True\n",
        "    \n",
        "    M = 4\n",
        "    \n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer(binary=True, min_df=M)\n",
        "        # Fit the vectorizer on the training data and transform both training and development data\n",
        "        featurized_data = vectorizer.fit_transform(data[\"text\"]).toarray()\n",
        "    else:\n",
        "        featurized_data = vectorizer.transform(data['text'])\n",
        "\n",
        "    #========================================================================#\n",
        "    #  This function should return the new data whose \"text\" feature contains\n",
        "    #  only 0 and 1\n",
        "    #========================================================================#\n",
        "\n",
        "    return featurized_data # Feel free to change the variable name\n",
        "\n",
        "# get the featurized data\n",
        "X_train   = bag_of_word(X_train_preproc)\n",
        "X_develop = bag_of_word(X_develop_preproc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set my M to 4 so that the words have more weights. Normally, setting M to 5 is preferable, but since I wanted a high performance, I lowered the M to 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReEOC-rkupXV"
      },
      "source": [
        "# Part (e): Logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vpjvSzoduu3O"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewpark/Library/Python/3.11/lib/python/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for training set: 0.93\n",
            "F1 for development set: 0.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewpark/Library/Python/3.11/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  You should complete the following function for logistic regression\n",
        "#  without regularization terms.\n",
        "#  You will be training logistic regression models using bag of words\n",
        "#  feature vectors obtained in part (d).\n",
        "#========================================================================#\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def logistic_without_regularization(X_train, Y_train, X_develop, Y_develop):\n",
        "    # initialize your logistic regression model\n",
        "    reg = LogisticRegression(penalty='none', max_iter=1000)\n",
        "\n",
        "    # then fit your model to the train data\n",
        "    reg.fit(X_train, Y_train)\n",
        "\n",
        "    # then generate your prediction for the training set\n",
        "    y_train_no_reg = reg.predict(X_train)\n",
        "\n",
        "    # then generate your prediction for the development set\n",
        "    y_develop_no_reg = reg.predict(X_develop)\n",
        "    #========================================================================#\n",
        "    #  This function should train a logistic regression model without\n",
        "    #  regularization terms.\n",
        "    #  Report the F1 score in your training and in your development sets.\n",
        "    #========================================================================#\n",
        "    return y_train_no_reg, y_develop_no_reg\n",
        "\n",
        "y_train_no_reg, y_develop_no_reg = logistic_without_regularization(X_train, y_train_orig, X_develop, y_develop_orig)\n",
        "\n",
        "# get the F1 train and develop scores\n",
        "F1_train_no_reg = sklearn.metrics.f1_score(y_train_orig, y_train_no_reg)\n",
        "F1_develop_no_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_no_reg)\n",
        "\n",
        "# print the F1 train and develop scores\n",
        "print(f\"F1 for training set: {F1_train_no_reg:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_no_reg:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The significant gap between the training set's high F1 score and the lower F1 score of the development set indicates overfitting, where the model has memorized the training data but struggles to generalize. To mitigate overfitting, consider gathering more diverse data, applying regularization techniques like L1 or L2, and fine-tuning hyperparameters through cross-validation. Additionally, simplifying the model architecture can make it less prone to overfitting, leading to improved generalization performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eaZwAJP6KUfv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for training set: 0.81\n",
            "F1 for development set: 0.73\n"
          ]
        }
      ],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  You should complete the following function for logistic regression\n",
        "#  with L1 regularization.\n",
        "#  You will be training logistic regression models using bag of words\n",
        "#  feature vectors obtained in part (d).\n",
        "#========================================================================#\n",
        "def logistic_L1_regularization(X_train, Y_train, X_develop, Y_develop):\n",
        "    # initialize your logistic regression model\n",
        "    reg = LogisticRegression(penalty = 'l1', solver='liblinear')\n",
        "\n",
        "    # then fit your model to the train data\n",
        "    reg.fit(X_train, Y_train)\n",
        "\n",
        "    # then generate your prediction for the training set\n",
        "    y_train_L1_reg = reg.predict(X_train)\n",
        "\n",
        "    # then generate your prediction for the development set\n",
        "    y_develop_L1_reg = reg.predict(X_develop)\n",
        "    #========================================================================#\n",
        "    #  This function should train a logistic regression model without\n",
        "    #  regularization terms.\n",
        "    #  Report the F1 score in your training and in your development sets.\n",
        "    #========================================================================#\n",
        "    return y_train_L1_reg, y_develop_L1_reg\n",
        "\n",
        "y_train_L1_reg, y_develop_L1_reg = logistic_L1_regularization(X_train, y_train_orig, X_develop, y_develop_orig)\n",
        "\n",
        "# get the F1 train and develop scores\n",
        "F1_train_L1_reg = sklearn.metrics.f1_score(y_train_orig, y_train_L1_reg)\n",
        "F1_develop_L1_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_L1_reg)\n",
        "\n",
        "# print the F1 train and develop scores\n",
        "print(f\"F1 for training set: {F1_train_L1_reg:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_L1_reg:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9PHKy8ElKVAg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for training set: 0.84\n",
            "F1 for development set: 0.73\n"
          ]
        }
      ],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  You should complete the following function for logistic regression\n",
        "#  with L2 regularization.\n",
        "#  You will be training logistic regression models using bag of words\n",
        "#  feature vectors obtained in part (d).\n",
        "#========================================================================#\n",
        "def logistic_L2_regularization(X_train, Y_train, X_develop, Y_develop):\n",
        "    # initialize your logistic regression model\n",
        "    reg = LogisticRegression(penalty='l2')\n",
        "\n",
        "    # then fit your model to the train data\n",
        "    reg.fit(X_train, Y_train)\n",
        "\n",
        "    # then generate your prediction for the training set\n",
        "    y_train_L2_reg = reg.predict(X_train)\n",
        "\n",
        "    # then generate your prediction for the development set\n",
        "    y_develop_L2_reg = reg.predict(X_develop)\n",
        "    #========================================================================#\n",
        "    #  This function should train a logistic regression model without\n",
        "    #  regularization terms.\n",
        "    #  Report the F1 score in your training and in your development sets.\n",
        "    #========================================================================#\n",
        "    return y_train_L2_reg, y_develop_L2_reg\n",
        "\n",
        "y_train_L2_reg, y_develop_L2_reg = logistic_L2_regularization(X_train, y_train_orig, X_develop, y_develop_orig)\n",
        "\n",
        "# get the F1 train and develop scores\n",
        "F1_train_L2_reg = sklearn.metrics.f1_score(y_train_orig, y_train_L2_reg)\n",
        "F1_develop_L2_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_L2_reg)\n",
        "\n",
        "# print the F1 train and develop scores\n",
        "print(f\"F1 for training set: {F1_train_L2_reg:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_L2_reg:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DmYQSKkK_L3"
      },
      "source": [
        "### Which one of the three classifiers performed the best on your training and development set? Did you observe any overfitting and did regularization help reduce it? Support your answers with the classifier performance you got."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYpWFNElLbWv"
      },
      "source": [
        "### Answer:\n",
        "Without Regulization = \\\n",
        "    F1 for training set: 0.93 \\\n",
        "    F1 for development set: 0.65\n",
        "\n",
        "L1 Regularization = \\\n",
        "    F1 for training set: 0.81 \\\n",
        "    F1 for development set: 0.73\n",
        "\n",
        "L2 Regularization = \\\n",
        "    F1 for training set: 0.84 \\\n",
        "    F1 for development set: 0.73\n",
        "\n",
        "The regularization method that yielded the lowest difference between F1 scores for the training set and development set, indicating better generalization to new data, was L1 regularization with an F1 score of 0.81 for the training set and 0.73 for the development set. This suggests that L1 regularization helps the model achieve more consistent performance on both the training and development data, making it a promising choice for handling new, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yysent_nLuh1"
      },
      "source": [
        "### Inspect the weight vector of the classifier with L1 regularization (in other words, look at the θ you got after training). You can access the weight vector of the trained model using the coef_attribute of a LogisticRegression instance. What are the most important words for deciding whether a tweet is about a real disaster or not? You might need to run some code (feel free to insert a code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: spill, Weight: 4.049948694779842\n",
            "Feature: outbreak, Weight: 3.918085900644332\n",
            "Feature: airport, Weight: 3.6959135655508537\n",
            "Feature: wreckage, Weight: 3.5905813287381183\n",
            "Feature: debris, Weight: 3.1986892649544223\n"
          ]
        }
      ],
      "source": [
        "N = 5  # 5 most important words\n",
        "\n",
        "inspect_L1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "inspect_L1.fit(X_train, y_train_orig)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "weights = inspect_L1.coef_[0]\n",
        "\n",
        "# Get the indices of the top N features with the highest absolute weights\n",
        "top_feature_indices = np.argsort(-np.abs(weights))[:N]\n",
        "\n",
        "for i in top_feature_indices:\n",
        "    print(f\"Feature: {feature_names[i]}, Weight: {weights[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ2S1QVCLwuY"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "The five most important words are 'spill', 'outbreak', 'airport', 'wreckage', and 'debris'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UWCsGNruvXD"
      },
      "source": [
        "# Part (f): Bernoulli Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wg7nMMI3u0HY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for training set: 0.78\n",
            "F1 for development set: 0.72\n"
          ]
        }
      ],
      "source": [
        "class BernoulliNB(object):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        #====================================================#\n",
        "        # YOUR CODE HERE:\n",
        "        #  You should build the Bernoully NB model from scratch\n",
        "        #  Do not use sklearn, use numpy and other basic packages\n",
        "        #    only.\n",
        "        #  Please update and save the parameters\n",
        "        #    \"self.class_log_prior_\" and \"self.feature_prob_\"\n",
        "        #  These variables are just a suggestion to help\n",
        "        #    structure your code - you do not need to use them\n",
        "        #    if you would prefer not to\n",
        "        #====================================================#\n",
        "        count_sample = X.shape[0]\n",
        "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
        "        self.class_log_prior_ = [np.log(len(i) / count_sample) for i in separated]\n",
        "        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n",
        "        smoothing = 2 * self.alpha\n",
        "        n_doc = np.array([len(i) + smoothing for i in separated])\n",
        "\n",
        "        self.feature_log_prob_ = np.log(count / n_doc[np.newaxis].T)\n",
        "        self.feature_log_prob_neg_ = np.log(1 / (1 + np.exp(self.feature_log_prob_)))\n",
        "        #====================================================#\n",
        "        # END YOUR CODE\n",
        "        #====================================================#\n",
        "        return self\n",
        "\n",
        "    def predict_log_prob(self, X):\n",
        "        #====================================================#\n",
        "        # YOUR CODE HERE:\n",
        "        #  You should build the Bernoully NB model from scratch\n",
        "        #  Do not use sklearn, use numpy and other basic packages\n",
        "        #    only.\n",
        "        #  Please update and save the parameters\n",
        "        #    \"self.pred_log_prob_\" and \"y_pred\"\n",
        "        #  These variables are just a suggestion to help\n",
        "        #    structure your code - you do not need to use them\n",
        "        #    if you would prefer not to\n",
        "        #====================================================#\n",
        "        positive_prob = X.dot(self.feature_log_prob_.T) \n",
        "        ones_matrix = np.ones(X.shape)\n",
        "        negative_prob = (ones_matrix - X).dot(self.feature_log_prob_neg_.T)\n",
        "\n",
        "        return positive_prob + negative_prob + np.array(self.class_log_prior_)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.predict_log_prob(X), axis=1)\n",
        "    \n",
        "        #====================================================#\n",
        "        # END YOUR CODE\n",
        "        #====================================================#\n",
        "        return y_pred\n",
        "\n",
        "# get the predictions y_train_NB and y_develop_NB\n",
        "nb = BernoulliNB(alpha=1)\n",
        "nb.fit(X_train, y_train_orig)\n",
        "y_train_NB = nb.predict(X_train) # prediction from X_train using model\n",
        "y_develop_NB = nb.predict(X_develop) # prediction from X_develop using model\n",
        "\n",
        "# Convert predictions to NumPy arrays\n",
        "y_train_NB = np.asarray(y_train_NB)\n",
        "y_develop_NB = np.asarray(y_develop_NB)\n",
        "\n",
        "# get the F1 train and develop scores\n",
        "F1_train_NB = sklearn.metrics.f1_score(y_train_orig, y_train_NB)\n",
        "F1_develop_NB = sklearn.metrics.f1_score(y_develop_orig, y_develop_NB)\n",
        "\n",
        "# print the F1 train and develop scores\n",
        "print(f\"F1 for training set: {F1_train_NB:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_NB:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JQrNzE6u0jY"
      },
      "source": [
        "# Part (g): Model comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7BcX1e7Ti0J"
      },
      "source": [
        "Question: Which model performed the best in predicting whether a tweet is of a real disaster or not? Include your performance metric in your response. Comment on the pros and cons of using generative vs discriminative models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7NDJXWFTn4m"
      },
      "source": [
        "Answer:\n",
        "\n",
        "Logistic Regression with L1 regularization (Discriminative Model)\\\n",
        "F1 for training set : 0.81\\\n",
        "F1 for development set : 0.73\n",
        "\n",
        "Bernoulli Naive Bayes (Generative Model)\\\n",
        "F1 for training set : 0.78\\\n",
        "F1 for development set : 0.72\n",
        "\n",
        "In my case, the Logistic Regression model outperformed the Bernoulli Naive Bayes model, which is not surprising given that Logistic Regression is known for its discriminative modeling capabilities and often works well for binary classification tasks. However, generative models can be valuable in certain scenarios, especially when dealing with limited data or when the independence assumptions align with the data's true structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTrNTtLgTpFM"
      },
      "source": [
        "Question: hink about the assumptions that Naive Bayes makes. How are the assumptions different from logistic regressions? Discuss whether it is valid and efficient to use Bernoulli Naive Bayes classifier for natural language texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvS8MuqBTqIR"
      },
      "source": [
        "Answer: In text classification for natural language processing, Bernoulli Naive Bayes leverages binary feature values, aligning well with the presence or absence of words in a document. Its simplicity and computational efficiency make it suitable for baseline models and resource-constrained scenarios. However, its significant limitation lies in the assumption of independence between words, which often doesn't hold in real-world texts due to complex word dependencies that contribute to overall meanings.\n",
        "\n",
        "In contrast, Logistic Regression doesn't explicitly assume feature independence, offering greater flexibility in capturing intricate relationships between words and their impact on the class label. This makes it more suitable for tasks where word dependencies matter, although it may require more data and computational resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46y89mf2u4q2"
      },
      "source": [
        "# Part (h): N-gram model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F7q6X9Geu8NB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andrewpark/Library/Python/3.11/lib/python/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 for training set: 0.51\n",
            "F1 for development set: 0.42\n",
            "F1 for training set: 0.51\n",
            "F1 for development set: 0.41\n",
            "F1 for training set: 0.54\n",
            "F1 for development set: 0.44\n",
            "F1 for training set: 0.51\n",
            "F1 for development set: 0.42\n"
          ]
        }
      ],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  Featurized the preprocessed data: X_train_preproc and X_develop_preproc\n",
        "#  using the N=2 gram model\n",
        "#========================================================================#\n",
        "\n",
        "vectorizer = None\n",
        "\n",
        "def n_gram(data):\n",
        "    global vectorizer\n",
        "    M = 4\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer(ngram_range=(2,2), binary=True, min_df=M)\n",
        "        n_gram_data = vectorizer.fit_transform(data[\"text\"]).toarray()\n",
        "    else:\n",
        "        n_gram_data = vectorizer.transform(data['text']).toarray()\n",
        "\n",
        "    #========================================================================#\n",
        "    # END CODE HERE\n",
        "    #  This function should return the new data whose \"text\" feature contains\n",
        "    #  only 0 and 1\n",
        "    #========================================================================#\n",
        "    return n_gram_data # Feel free to change the variable name\n",
        "\n",
        "# get the featurized data\n",
        "X_train_gram   = n_gram(X_train_preproc)\n",
        "X_develop_gram = n_gram(X_develop_preproc)\n",
        "\n",
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  Use the functions you already defined \"X_train_gram\" and \"X_develop_gram\"\n",
        "#  to re-run:\n",
        "#  Logistic Regression with no regularization Model\n",
        "#  Logistic Regression with L1 regularization Model\n",
        "#  Logistic Regression with L2 regularization Model\n",
        "#========================================================================#\n",
        "y_train_gram_no_reg, y_develop_gram_no_reg = logistic_without_regularization(X_train_gram, y_train_orig, X_develop_gram, y_develop_orig)\n",
        "y_train_gram_L1_reg, y_develop_gram_L1_reg = logistic_L1_regularization(X_train_gram, y_train_orig, X_develop_gram, y_develop_orig)\n",
        "y_train_gram_L2_reg, y_develop_gram_L2_reg = logistic_L2_regularization(X_train_gram, y_train_orig, X_develop_gram, y_develop_orig)\n",
        "nb.fit(X_train_gram, y_train_orig)\n",
        "y_train_gram_NB = nb.predict(X_train_gram)\n",
        "y_develop_gram_NB = nb.predict(X_develop_gram)\n",
        "\n",
        "y_develop_gram_NB = np.asarray(y_develop_gram_NB)\n",
        "#========================================================================#\n",
        "# END CODE HERE\n",
        "#========================================================================#\n",
        "\n",
        "# get the F1 train and develop scores for no regularization model\n",
        "F1_train_gram_no_reg = sklearn.metrics.f1_score(y_train_orig, y_train_gram_no_reg)\n",
        "F1_develop_gram_no_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_gram_no_reg)\n",
        "# get the F1 train and develop scores for L1 regularization model\n",
        "F1_train_gram_L1_reg = sklearn.metrics.f1_score(y_train_orig, y_train_gram_L1_reg)\n",
        "F1_develop_gram_L1_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_gram_L1_reg)\n",
        "# get the F1 train and develop scores for L2 regularization model\n",
        "F1_train_gram_L2_reg = sklearn.metrics.f1_score(y_train_orig, y_train_gram_L2_reg)\n",
        "F1_develop_gram_L2_reg = sklearn.metrics.f1_score(y_develop_orig, y_develop_gram_L2_reg)\n",
        "# get the F1 train and develop scores for Bernoulli NB model\n",
        "F1_train_gram_NB = sklearn.metrics.f1_score(y_train_orig, y_train_gram_NB)\n",
        "F1_develop_gram_NB = sklearn.metrics.f1_score(y_develop_orig, y_develop_gram_NB)\n",
        "\n",
        "# print the F1 train and develop scores for no regularization model\n",
        "print(f\"F1 for training set: {F1_train_gram_NB:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_gram_NB:.2f}\")\n",
        "# print the F1 train and develop scores for L1 regularization model\n",
        "print(f\"F1 for training set: {F1_train_gram_L1_reg:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_gram_L1_reg:.2f}\")\n",
        "# print the F1 train and develop scores for L2 regularization model\n",
        "print(f\"F1 for training set: {F1_train_gram_L2_reg:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_gram_L2_reg:.2f}\")\n",
        "# print the F1 train and develop scores for Bernoulli NB model\n",
        "print(f\"F1 for training set: {F1_train_gram_NB:.2f}\")\n",
        "print(f\"F1 for development set: {F1_develop_gram_NB:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of 2-grams in vocabulary: 708\n",
            "First 5 2-grams from vocabulary: aba woman, abandoned aircraft, abc news, access secret, accident expert\n"
          ]
        }
      ],
      "source": [
        "# Get the vocabulary\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Calculate the total number of 2-grams in the vocabulary\n",
        "num_2grams = len(vocab)\n",
        "\n",
        "# Get the first 5 2-grams from the vocabulary\n",
        "vocab_5 = vocab[:5]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total number of 2-grams in vocabulary: {num_2grams}\")\n",
        "print(f\"First 5 2-grams from vocabulary: {', '.join(vocab_5)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When determining the appropriate threshold value, M, for a model, it is a standard practice to consider the frequency of terms or n-grams. Striking the right balance between retaining rare n-grams and filtering out less relevant 2-grams is crucial. In this context, I decided to set M at 4. This choice is often guided by a widely accepted heuristic, which posits that a word should appear in multiple tweets to be considered significant.\n",
        "\n",
        "Overall, the bag of words outperformed every single models compared to n gram function both training and development set. The reason for this might be the way n gram model captures texts in a 2-grams form. This might be good at capturing local context betweed words, but in this case, since tweets are short, it seems to be not that efficient to carry more weight on each words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55QmSb3ku8oa"
      },
      "source": [
        "# Part (i): Determine performance with the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i270_AqVvAbH"
      },
      "outputs": [],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  Re-build your feature vectors on the entire Kaggle train set\n",
        "#  (i.e. DO NOT split the train set into a further train set and development set)\n",
        "#========================================================================#\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data  = pd.read_csv('test.csv')\n",
        "\n",
        "# get train data\n",
        "X_train    = train_data.drop(columns= 'target')\n",
        "y_train    = train_data['target']\n",
        "\n",
        "# get test data\n",
        "X_test     = test_data\n",
        "\n",
        "# Preprocess\n",
        "X_train['text']   = X_train['text'].apply(pre_process)\n",
        "X_test['text'] = X_test['text'].apply(pre_process)\n",
        "\n",
        "#========================================================================#\n",
        "# END CODE HERE\n",
        "#========================================================================#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u985um3AY1ie"
      },
      "outputs": [],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  Re-train your preferred classifier (see below) on the entire train set\n",
        "#  (i.e. DO NOT split the train set into a further train set and development set)\n",
        "#  Your preferred classifier may inculde either bag of word or n-gram,\n",
        "#  and using either logistic regression or Bernoulli naive bayes\n",
        "#========================================================================#\n",
        "\n",
        "# Bag of Words \n",
        "X_train_text = bag_of_word(X_train)\n",
        "X_test_text = bag_of_word(X_test)\n",
        "\n",
        "# Fitting L1 regulization \n",
        "reg = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "reg.fit(X_train_text, y_train)\n",
        "\n",
        "# Prediction on test set\n",
        "y_test_L1_reg = reg.predict(X_test_text)\n",
        "\n",
        "#========================================================================#\n",
        "# END CODE HERE\n",
        "#========================================================================#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6CIKyutPY1zL"
      },
      "outputs": [],
      "source": [
        "#=======================================================================+#\n",
        "# YOUR CODE HERE:\n",
        "#  Report the resulting F 1-score on the test data, as reported by Kaggle\n",
        "#========================================================================#\n",
        "\n",
        "pred_df = pd.DataFrame(y_test_L1_reg, columns=['target']) \n",
        "to_submit = pd.concat([X_test['id'], pred_df], axis=1)\n",
        "to_submit['id'] = to_submit['id'].astype(int)\n",
        "\n",
        "to_submit.to_csv('results.csv', index=False)\n",
        "\n",
        "#========================================================================#\n",
        "# END CODE HERE\n",
        "#========================================================================#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Results](kaggle.png)\n",
        "\n",
        "For the kaggle result, the score was 0.692. Considering the fact that I have chosen the best models for my prediction (bag of words, L1 regulization), I expected a higher score. There might be several reasons for this result, and one of them is maybe some randomness has been included in the model it self."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
